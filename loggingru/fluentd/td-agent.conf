<match fluent.**>
  type null
</match>

<source>
  type tail
  format json
  time_key time
  path /var/lib/docker/containers/*/*.log
  pos_file /var/log/es-containers.log.pos
  time_format %Y-%m-%dT%H:%M:%S.%NZ
  tag kubernetes.*
  read_from_head true
</source>


<filter kubernetes.**>
  type kubernetes_metadata
</filter>

<match **>
   # This is expensive, but allows to separate logs by namespace
   type elasticsearch_dynamic
   num_threads 8
   log_level info
   logstash_dateformat "%Y.%m.%d"
   include_tag_key true
   host elasticsearch.loggingru
   port 9200
   logstash_format true
   logstash_prefix logstash-match-${record['kubernetes']['namespace_name']}
   # Set the chunk limit the same as for fluentd-gcp.
   buffer_chunk_limit 50M
   # Cap buffer memory usage to 512KB/chunk * 128 chunks = 65 MB
   buffer_queue_limit 32
   flush_interval 5s
   buffer_type memory
   retry_wait 1.0
   # Never wait longer than 5 minutes between retries.
   max_retry_wait 300
   # Disable the limit on the number of retries (retry forever).
   disable_retry_limit
   reload_connections true
   reload_on_failure true
   resurrect_after 5
</match>



<match kubernetes.**>
   type elasticsearch_dynamic
   num_threads 8
   logstash_dateformat "%Y.%m.%d"
   log_level info
   include_tag_key true
   host elasticsearch.loggingru
   port 9200
   logstash_format true
   logstash_prefix logstash-homek8s-${record['kubernetes']['namespace_name']}
   # Set the chunk limit the same as for fluentd-gcp.
   buffer_chunk_limit 50M
   # Cap buffer memory usage to 512KB/chunk * 128 chunks = 65 MB
   buffer_queue_limit 32
   flush_interval 5s
   buffer_type memory
   retry_wait 1.0
   # Never wait longer than 5 minutes between retries.
   max_retry_wait 300
   # Disable the limit on the number of retries (retry forever).
   disable_retry_limit
   reload_connections true
   reload_on_failure true
   resurrect_after 5
</match>
